{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Statistics__ is the branch of mathematics dealing with the collection, analysis, interpretation,\n",
    "presentation, and organization of numerical data.\n",
    "\n",
    "Statistics are mainly classified into two subbranches:\n",
    "1. __Descriptive statistics__: These are used to summarize data, such as the mean,\n",
    "standard deviation for continuous data types (such as age), whereas frequency\n",
    "and percentage are useful for categorical data (such as gender).\n",
    "2. __Inferential statistics__: Many times, a collection of the entire data (also known as\n",
    "population in statistical methodology) is impossible, hence a subset of the data\n",
    "points is collected, also called a sample, and conclusions about the entire\n",
    "population will be drawn, which is known as inferential statistics. Inferences are\n",
    "drawn using hypothesis testing, the estimation of numerical characteristics, the\n",
    "correlation of relationships within data, and so on.\n",
    "\n",
    "__Machine learning__ is the branch of computer science that utilizes past experience to learn\n",
    "from and use its knowledge to make future decisions. Machine learning is at the\n",
    "intersection of computer science, engineering, and statistics. The goal of machine learning is\n",
    "to generalize a detectable pattern or to create an unknown rule from given examples\n",
    "\n",
    "1. __Supervised learning__: This is teaching machines to learn the relationship between\n",
    "other variables and a target variable. The major segments within\n",
    "supervised learning are as follows:\n",
    "    1. Classification problem\n",
    "    2. Regression problem\n",
    "2. __Unsupervised learning__: In unsupervised learning, algorithms learn by\n",
    "themselves without any supervision or without any target variable provided. It is\n",
    "a question of finding hidden patterns and relations in the given data. The\n",
    "categories in unsupervised learning are as follows:\n",
    "    1. Dimensionality reduction\n",
    "    2. Clustering\n",
    "3. __Reinforcement learning__: This allows the machine or agent to learn its behavior\n",
    "based on feedback from the environment. In reinforcement learning, the agent\n",
    "takes a series of decisive actions without supervision and, in the end, a reward\n",
    "will be given, either +1 or -1. Based on the final payoff/reward, the agent\n",
    "reevaluates its paths. Reinforcement learning problems are closer to the artificial\n",
    "intelligence methodology rather than frequently used machine learning\n",
    "algorithms.\n",
    "\n",
    "Difference between Statistics and ML:\n",
    "1. Relationships are formed in forms of mathematical equations in statistics whereas in ML it is formed in the form of rule-based programming. \n",
    "2. Statistical model predicts the output with Machine learning just predicts the output with accuracy of 85 percent and having 90 percent confidence about it. Machine learning just predicts the output with accuracy of 85 percent.\n",
    "3. Statistics  -  Data will be split into 70 percent - 30 percent to create training and testing data. Model developed on training data and tested on testing data. ML - Data will be split into 50 percent - 25 percent - 25 percent to create training, validation, andtesting data. Models developed on training and hyperparameters are tuned on validation data and finally get evaluated against test data.\n",
    "\n",
    "Steps in building ML Model:\n",
    "1. Collection of Data\n",
    "2. Data preparation and outlier treatment\n",
    "3. Data Analysis and Feature Engineering\n",
    "4. Train algorithm on training and validation data\n",
    "5. Test algorithm on test data\n",
    "6. Deploy algorithm\n",
    "\n",
    "__Statistics Fundamentals__\n",
    "1. __Population__: This is the totality, the complete list of observations, or all the data\n",
    "points about the subject under study.\n",
    "2. __Sample__:A sample is a subset of a population, usually a small portion of the\n",
    "population that is being analyzed.\n",
    "3. __Parameter versus Statistic__: Any measure that is calculated on the population is a\n",
    "parameter, whereas on a sample it is called a statistic.\n",
    "4. __Mean__: Arithmetic average. The mean is sensitive to outliers in the data. An outlier is the value of a set or column that is highly deviant from the many other values in the same data; it usually has very high or low values.\n",
    "5. __Median__:This is the midpoint of the data, and is calculated by either arranging it in ascending or descending order. If there are N observations.\n",
    "6. __Mode__:This is the most repetitive data point in the data.\n",
    "\n",
    "<img src=\"images/mean_median_mode.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([4, 5, 1, 6, 8, 1, 3, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.555555555555555"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(data)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = np.median(data)\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = stats.mode(data)\n",
    "mode[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. __Measure of Variation__:Dispersion is the variation in the data, and measures the inconsistencies in the value of variables in the data.\n",
    "8. __Range__:Difference between the maximum and minimum of the value.\n",
    "9. __Variance__: This is the mean of squared deviations from the mean. The dimension of variance is the square of the actual values. The reason to use denominator N-1 for a sample instead of N in the population is due the degree of freedom. 1 degree of freedom lost in a sample by the time of calculating variance is due to extraction of substitution of sample. \n",
    "10. __Standard Deviation__: This is the square root of variance. By applying the square root on variance, we measure the dispersion with respect to the original variable rather than square of the dimension. \n",
    "11. __Quantiles__:These are identical fragments of the data. Quantiles cover percentiles, deciles, quartiles, and so on. These measures are calculated after arranging the data in ascending order\n",
    "    1. __Percentile__:This is the percentage of data points below the value of the original whole data. The median is the 50 th percentile, as the number of data points below the median is about 50 percent of the data.\n",
    "    2. __Decile__: This is 10th percentile, which means the number of data points below the decile is 10 percent of the whole data.\n",
    "    3. __Quartile__: This is one-fourth of the data, and also is the 25 percentile. The first quartile is 25 percent of the data, the second quartile is 50 percent of the data, the third quartile is 75 percent of the data. The second quartile is also known as the median or 50 th percentile or 5 th decile.\n",
    "    4. __Interquartile Range__: This is the difference between the third quartile and first quartile. It is effective in identifying outliers in data. The interquartile range describes the middle 50 percent of the data points.\n",
    "    \n",
    "    <img src=\"images/quantile.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import variance, stdev\n",
    "game_points = np.array([35, 46, 72, 38, 81, 41, 57, 93, 17, 33, 61, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance\n",
    "variance_data = variance(game_points)\n",
    "variance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.825424421026653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Deviation\n",
    "standard_dev = stdev(game_points)\n",
    "standard_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range\n",
    "range_data = np.max(game_points, axis=0) - np.min(game_points, axis=0)\n",
    "range_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 % : 33.199999999999996\n",
      "20 % : 35.6\n",
      "30 % : 38.900000000000006\n",
      "40 % : 43.0\n",
      "50 % : 51.5\n",
      "60 % : 59.4\n",
      "70 % : 68.69999999999999\n",
      "80 % : 74.4\n",
      "90 % : 80.4\n"
     ]
    }
   ],
   "source": [
    "# Quantile\n",
    "for val in [10, 20, 30, 40, 50, 60, 70, 80, 90]:\n",
    "    quant = np.percentile(game_points, val)\n",
    "    print(val, '% :', quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. __Hypothesis Testing__: This is the process of making inferences about the overall population by conducting some statistical tests on a sample. Null and alternate hypotheses are ways to validate whether an assumption is statistically significant or not.\n",
    "13. __P-Value__: The probability of obtaining a test statistic result is at least as extreme as the one that was actually observed, assuming that the null hypothesis is true (usually in modeling, against each independent variable, a p-value less than 0.05 is considered significant and greater than 0.05 is considered insignificant; nonetheless, these values and definitions may change with respect to context).\n",
    "\n",
    "P value less than 0.05 means both claimed values and distribution mean values are significantly different, hence we can reject null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Steps involved in Hypothesis Testing__\n",
    "1. Assume a null hypothesis (usually no difference, no significance, and so on; a null hypothesis always tries to assume that there is no anomaly pattern and is always homogeneous, and so on).\n",
    "2. Collect the sample.\n",
    "3. Calculate test statistics from the sample in order to verify whether the hypothesis is statistically significant or not.\n",
    "4. Decide either to accept or reject the null hypothesis based on the test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test Statistic and Critical Value__\n",
    "In hypothesis testing, a critical value is a point on test distribution that is compared to the test statistic to determine whether to reject null hypothesis. If absolute value of test statistic is greater than critical value, then it would be correct to declare statistical significance and reject null hypothesis. Critical values correspond to alpha, so their values become fixed when we chosse the test's alpha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.381780460041329"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "xbar = 990\n",
    "mu0 = 1000\n",
    "s = 12.5\n",
    "n = 30\n",
    "# Test Statistic\n",
    "t_smple = (xbar-mu0)/(s/np.sqrt(float(n)))\n",
    "t_smple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6991270265334977"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Critical Value\n",
    "alpha = 0.05\n",
    "t_alpha = stats.t.ppf(alpha, n-1)\n",
    "t_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.035025729010886e-05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P Value\n",
    "p_val = stats.t.sf(np.abs(t_smple), n-1)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. __Type I and Type II Error__: Hypothesis testing is usually done on the samples rather\n",
    "than the entire population, due to the practical constraints of available resources\n",
    "to collect all the available data. However, performing inferences about the\n",
    "population from samples comes with its own costs, such as rejecting good results\n",
    "or accepting false results, not to mention separately, when increases in sample\n",
    "size lead to minimizing type I and II errors:\n",
    "    1. __Type I error__: Rejecting a null hypothesis when it is true\n",
    "    2. __Type II error__: Accepting a null hypothesis when it is false\n",
    "    \n",
    "15. __Normal Distribution__:This is very important in statistics because of the central limit theorem, which states that the population of all possible samples of size n from a population with mean μ and variance σ2 approaches a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.920245398773006"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z-Score\n",
    "xbar = 67\n",
    "mu0 = 52\n",
    "s = 16.3\n",
    "z = (xbar-mu0)/s\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.872226751475175"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability Under Curve \n",
    "p_val = 1 - stats.norm.cdf(z)\n",
    "p_val*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. __Chi-square__:This test of independence is one of the most basic and common hypothesis tests in the statistical analysis of categorical data. Given two categorical random variables X and Y, the chi-square test of independence determines whether or not there exists a statistical dependence between them.\n",
    "\n",
    "The test is usually performed by calculating χ2 from the data and χ2 with\n",
    "(m-1, n-1) degrees from the table. A decision is made as to whether both\n",
    "variables are independent based on the actual value and table value,\n",
    "whichever is higher.\n",
    "\n",
    "<img src=\"images/chi-square.png\">\n",
    "\n",
    "The chi2_contingency function in the stats package uses the observed table and subsequently calculates its expected table, followed by calculating the p-value in order to check whether two variables are dependent or not. If p-value < 0.05, there is a strong dependency between two variables, whereas if p-value > 0.05, there is no dependency between the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Wr.Hnd</th>\n",
       "      <th>NW.Hnd</th>\n",
       "      <th>W.Hnd</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Clap</th>\n",
       "      <th>Exer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Height</th>\n",
       "      <th>M.I</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Right</td>\n",
       "      <td>R on L</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Left</td>\n",
       "      <td>Some</td>\n",
       "      <td>Never</td>\n",
       "      <td>173.0</td>\n",
       "      <td>Metric</td>\n",
       "      <td>18.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Left</td>\n",
       "      <td>R on L</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Left</td>\n",
       "      <td>None</td>\n",
       "      <td>Regul</td>\n",
       "      <td>177.8</td>\n",
       "      <td>Imperial</td>\n",
       "      <td>17.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>Right</td>\n",
       "      <td>L on R</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>None</td>\n",
       "      <td>Occas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.9</td>\n",
       "      <td>Right</td>\n",
       "      <td>R on L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neither</td>\n",
       "      <td>None</td>\n",
       "      <td>Never</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Metric</td>\n",
       "      <td>20.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Right</td>\n",
       "      <td>Neither</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Right</td>\n",
       "      <td>Some</td>\n",
       "      <td>Never</td>\n",
       "      <td>165.0</td>\n",
       "      <td>Metric</td>\n",
       "      <td>23.667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Wr.Hnd  NW.Hnd  W.Hnd     Fold  Pulse     Clap  Exer  Smoke  \\\n",
       "0  Female    18.5    18.0  Right   R on L   92.0     Left  Some  Never   \n",
       "1    Male    19.5    20.5   Left   R on L  104.0     Left  None  Regul   \n",
       "2    Male    18.0    13.3  Right   L on R   87.0  Neither  None  Occas   \n",
       "3    Male    18.8    18.9  Right   R on L    NaN  Neither  None  Never   \n",
       "4    Male    20.0    20.0  Right  Neither   35.0    Right  Some  Never   \n",
       "\n",
       "   Height       M.I     Age  \n",
       "0   173.0    Metric  18.250  \n",
       "1   177.8  Imperial  17.583  \n",
       "2     NaN       NaN  16.917  \n",
       "3   160.0    Metric  20.333  \n",
       "4   165.0    Metric  23.667  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from scipy import stats\n",
    "\n",
    "survey = pd.read_csv('Data Files/survey.csv')\n",
    "survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Exer</th>\n",
       "      <th>Freq</th>\n",
       "      <th>None</th>\n",
       "      <th>Some</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heavy</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Never</th>\n",
       "      <td>87</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occas</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regul</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>115</td>\n",
       "      <td>23</td>\n",
       "      <td>98</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Exer   Freq  None  Some  All\n",
       "Smoke                       \n",
       "Heavy     7     1     3   11\n",
       "Never    87    18    84  189\n",
       "Occas    12     3     4   19\n",
       "Regul     9     1     7   17\n",
       "All     115    23    98  236"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_tab = pd.crosstab(survey['Smoke'], survey['Exer'], margins=True)\n",
    "survey_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Exer</th>\n",
       "      <th>Freq</th>\n",
       "      <th>None</th>\n",
       "      <th>Some</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heavy</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Never</th>\n",
       "      <td>87</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occas</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regul</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Exer   Freq  None  Some\n",
       "Smoke                  \n",
       "Heavy     7     1     3\n",
       "Never    87    18    84\n",
       "Occas    12     3     4\n",
       "Regul     9     1     7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = survey_tab.iloc[0:4, 0:3]\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.483"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contg = stats.chi2_contingency(observed=observed)\n",
    "p_value = round(contg[1], 3)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.483 , which means there is no dependency between the smoking habit and exercise behavior.\n",
    "\n",
    "Stats.Chi2_Contingency returns following:\n",
    "1. Test Statistics\n",
    "2. P Value\n",
    "3. Degree of Freedom "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. __ANOVA__:Analyzing variance tests the hypothesis that the means of two or more populations are equal. ANOVAs assess the importance of one or more factors by comparing the response variable means at the different factor levels. The null hypothesis states that all population means are equal while the alternative hypothesis states that at least one is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fertilizer1</th>\n",
       "      <th>fertilizer2</th>\n",
       "      <th>fertilizer3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>58</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fertilizer1  fertilizer2  fertilizer3\n",
       "0           62           54           48\n",
       "1           62           56           62\n",
       "2           90           58           92\n",
       "3           42           36           96\n",
       "4           84           72           92"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "data = pd.read_csv('Data Files/fetilizers.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic : 3.66 , p-value: 0.051\n"
     ]
    }
   ],
   "source": [
    "# One-Way ANOVA\n",
    "one_way_anova = stats.f_oneway(data['fertilizer1'], data['fertilizer2'], data['fertilizer3'])\n",
    "print (\"Statistic :\", round(one_way_anova[0],2),\", p-value:\",round(one_way_anova[1],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value did come equal to 0.05, hence we accept the null hypothesis that the mean crop yields of the fertilizers are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. __Confusion Matrix__:This is the matrix of the actual versus the predicted. The table contains following:\n",
    "    1. __True positives (TPs)__: True positives are cases when we predict the outcome(class) and it is correct.\n",
    "    2. __True negatives (TNs)__: Cases when we predict the outcome (class) and the class is actually not there.\n",
    "    3. __False positives (FPs)__: When we predict the outcome as yes when the outcome actually does not have it. FPs are also considered to be type I errors.\n",
    "    4. __False negatives (FNs)__: When we predict the outcome as no when the outcome actually does have it. FNs are also considered to be type II errors.\n",
    "    5. __Precision (P)__: When yes is predicted, how often is it correct? (TP/TP+FP)\n",
    "    6. __Recall (R)/sensitivity/true positive rate__: Among the actual yeses, what fraction was predicted as yes? (TP/TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
